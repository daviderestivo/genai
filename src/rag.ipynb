{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6487917-bade-4129-8f03-59d139b40d0e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4145cc-fb59-4f18-9903-475e6e65c9fe",
   "metadata": {},
   "source": [
    "<img src=\"imgs/RAG.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a407d2-b603-406b-89dc-903cdd1f3ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LiteLLM (https://github.com/BerriAI/litellm)\n",
    "\n",
    "# Uncomment the below line to install litellm\n",
    "# !pip install litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924d37b7-e696-416b-a113-00269edfc8cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This is an example CURL call for LM Studio using an embedding model:\n",
    "\n",
    "curl http://127.0.0.1:1234/v1/embeddings \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\n",
    "    \"model\": \"text-embedding-granite-embedding-278m-multilingual\",\n",
    "    \"input\": \"Some text to embed\"\n",
    "  }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c6f6d0-06db-4e9b-bf2d-13c124347ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json, os\n",
    "\n",
    "#\n",
    "# LM Studio URL \n",
    "#\n",
    "# Embeddings\n",
    "EMBEDDING_MODEL = \"text-embedding-granite-embedding-278m-multilingual\"\n",
    "LMSTUDIO_EMBEDDINGS_URL = \"http://127.0.0.1:1234/v1/embeddings\"\n",
    "# LLM\n",
    "os.environ['LM_STUDIO_API_BASE'] = \"http://localhost:1234/v1\"\n",
    "os.environ['LM_STUDIO_API_KEY'] = \"42\" # Not really used. Set it to a non empty value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbc20c6-1fcc-46b6-b78b-3737483dcdec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"object\": \"embedding\",\n",
      "      \"embedding\": [\n",
      "        -0.014949378557503223,\n",
      "        -0.03729313239455223,\n",
      "        -0.06780612468719482,\n",
      "        0.017350835\n"
     ]
    }
   ],
   "source": [
    "data = { \"model\": EMBEDDING_MODEL, \"input\": \"Some text to embed\" }\n",
    "\n",
    "response = requests.post(LMSTUDIO_EMBEDDINGS_URL, json=data)\n",
    "print(response.text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daee118c-f231-40ef-afda-7d428649d5df",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Install ChromaDB vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540fc153-0f30-47b0-b553-35a27f003119",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install ChromaDB Pyhton library\n",
    "# ! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f300d40e-7cdb-4245-bc85-a9c9e6bfb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "collection_name = \"collection00\"\n",
    "client = chromadb.Client()\n",
    "\n",
    "if collection_name in [coll.name for coll in client.list_collections()]:\n",
    "    client.delete_collection(name=collection_name)\n",
    "    print(f\"Collection '{collection_name}' deleted.\")\n",
    "else:\n",
    "    collection = client.create_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6989882-9323-4db5-9a23-ec6e28e47c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = \"The capital of Italy is Milan.\"\n",
    "data1 = { \"model\": EMBEDDING_MODEL, \"input\": input1 }\n",
    "response1 = requests.post(LMSTUDIO_EMBEDDINGS_URL, json=data1)\n",
    "embedding1 = response1.json()[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0abc8d5-5276-4f09-beba-7b792663fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = \"The total population of Milan is 10 people.\"\n",
    "data2 = { \"model\": EMBEDDING_MODEL, \"input\": input2 }\n",
    "response2 = requests.post(LMSTUDIO_EMBEDDINGS_URL, json=data2)\n",
    "embedding2 = response2.json()[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f679609-5152-455f-a2f3-247dddfa52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input3 = \"An horse has 4 legs and a tail\"\n",
    "data3 = { \"model\": EMBEDDING_MODEL, \"input\": input3 }\n",
    "response3 = requests.post(LMSTUDIO_EMBEDDINGS_URL, json=data3)\n",
    "embedding3 = response3.json()[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c3e0d3-004f-4599-b54f-cefb5e44a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(documents=[input1], embeddings=[embedding1], ids=[\"id1\"])\n",
    "collection.add(documents=[input2], embeddings=[embedding2], ids=[\"id2\"])\n",
    "collection.add(documents=[input3], embeddings=[embedding3], ids=[\"id3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5528b9a-623f-4024-903a-d47ac6535551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id1', 'id2', 'id3'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['The capital of Italy is Milan.',\n",
       "  'The total population of Milan is 10 people.',\n",
       "  'An horse has 4 legs and a tail'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [None, None, None]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e15a23b3-1a39-4bed-9c28-400beba719fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion \n",
    "from typing import List, Dict\n",
    "\n",
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"Call LLM to get a response.\"\"\"\n",
    "    response = completion(\n",
    "        model=\"lm_studio/lmstudio\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d9b519-57c5-4bcb-871a-f02ceb2e1664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How can I help you today? what's the capital of Italy?\n"
     ]
    }
   ],
   "source": [
    "user_input = input(\"How can I help you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97331f08-3ece-4370-acb3-c4962fded3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04225713759660721,\n",
       " 0.052123963832855225,\n",
       " -0.01851440779864788,\n",
       " 0.0545511320233345,\n",
       " -0.004544607363641262,\n",
       " -0.03987252712249756,\n",
       " 0.07662363350391388,\n",
       " 0.05532529950141907,\n",
       " 0.011184877716004848,\n",
       " 0.007382847368717194]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data = { \"model\": EMBEDDING_MODEL, \"input\": user_input }\n",
    "response = requests.post(LMSTUDIO_EMBEDDINGS_URL, json=user_data)\n",
    "embedding = response.json()[\"data\"][0][\"embedding\"]\n",
    "embedding[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a47d2a-9194-4a5d-a393-e315ac794d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search in ChromaDB\n",
    "results = collection.query(\n",
    "    query_embeddings=[embedding],\n",
    "    n_results=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab53c2c0-54c0-43e2-9c41-de565f231edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The capital of Italy is Milan.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's only keep the doc with cosine distance < 0.3\n",
    "filtered_docs = [\n",
    "    doc\n",
    "    for doc, dist in zip(results[\"documents\"][0], results[\"distances\"][0])\n",
    "    if dist < 0.3\n",
    "]\n",
    "filtered_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "131a1ea9-6f89-430f-9746-ccf67c8bfb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a helpful assistant that uses the following context to answer the user's question.\"},\n",
       " {'role': 'system', 'content': 'Context:\\nThe capital of Italy is Milan.'},\n",
       " {'role': 'user', 'content': \"what's the capital of Italy?\"}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most RAG setups inject retrieved context as a system message \n",
    "# (or as part of the user message, depending on the model).\n",
    "\n",
    "# Let's construct the prompt:\n",
    "retrieved_text = \" \".join(filtered_docs)\n",
    "memory = [\n",
    "  {\"role\": \"system\", \"content\": \"You are a helpful assistant that uses the following context to answer the user's question.\"},\n",
    "  {\"role\": \"system\", \"content\": \"Context:\\n\" + retrieved_text},\n",
    "  {\"role\": \"user\", \"content\": user_input}\n",
    "]\n",
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b3ee47f-270b-4492-baa1-42d0056fc9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to my information, the capital of Italy is Milan.\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(memory)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefea4bc-24b5-44a2-86b3-b2f45ad1baea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
