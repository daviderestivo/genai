{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55d4c83-092a-49c5-bda0-cd41fa0544d5",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a099dd8-d599-4255-a150-4fefe28b0d07",
   "metadata": {},
   "source": [
    "Make sure you have 'LM Studio' running locally. 'LM Studio' loaded models listen on:\n",
    "`http://localhost:1234/v1/chat/completions`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02864195-a8d6-47c9-8a25-7ad41e2edca1",
   "metadata": {},
   "source": [
    "# Install required Python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767f17c-6e82-493d-9eaa-ae6c51873826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LiteLLM (https://github.com/BerriAI/litellm)\n",
    "\n",
    "# Uncomment the below line to install litellm\n",
    "# !pip install litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69cfcb4-a6d6-4b16-8db8-89730f5e2b43",
   "metadata": {},
   "source": [
    "# Code samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ad220-67c1-4780-af94-07a6b7bd4122",
   "metadata": {},
   "source": [
    "## An Invoice Processing Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f7a32-e229-419b-8ae8-5987dd25cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Imports ...\n",
    "#\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import traceback\n",
    "import inspect\n",
    "from litellm import completion\n",
    "from dataclasses import dataclass, field\n",
    "from typing import get_type_hints, List, Callable, Dict, Any\n",
    "\n",
    "#\n",
    "# LM Studio URL \n",
    "#\n",
    "os.environ['LM_STUDIO_API_BASE'] = \"http://localhost:1234/v1\"\n",
    "os.environ['LM_STUDIO_API_KEY'] = \"42\" # Not really used. Set it to a non empty value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11694a24-4e84-414e-b8b5-0f4919a0d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = {}\n",
    "tools_by_tag = {}\n",
    "\n",
    "def to_openai_tools(tools_metadata: List[dict]):\n",
    "    openai_tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": t['tool_name'],\n",
    "                # Include up to 1024 characters of the description\n",
    "                \"description\": t.get('description',\"\")[:1024],\n",
    "                \"parameters\": t.get('parameters',{}),\n",
    "            },\n",
    "        } for t in tools_metadata\n",
    "    ]\n",
    "    return openai_tools\n",
    "\n",
    "def get_tool_metadata(func, tool_name=None, description=None, parameters_override=None, terminal=False, tags=None):\n",
    "    \"\"\"\n",
    "    Extracts metadata for a function to use in tool registration.\n",
    "\n",
    "    Parameters:\n",
    "        func (function): The function to extract metadata from.\n",
    "        tool_name (str, optional): The name of the tool. Defaults to the function name.\n",
    "        description (str, optional): Description of the tool. Defaults to the function's docstring.\n",
    "        parameters_override (dict, optional): Override for the argument schema. Defaults to dynamically inferred schema.\n",
    "        terminal (bool, optional): Whether the tool is terminal. Defaults to False.\n",
    "        tags (List[str], optional): List of tags to associate with the tool.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the tool, including description, args schema, and the function.\n",
    "    \"\"\"\n",
    "    # Default tool_name to the function name if not provided\n",
    "    tool_name = tool_name or func.__name__\n",
    "\n",
    "    # Default description to the function's docstring if not provided\n",
    "    description = description or (func.__doc__.strip() if func.__doc__ else \"No description provided.\")\n",
    "\n",
    "    # Discover the function's signature and type hints if no args_override is provided\n",
    "    if parameters_override is None:\n",
    "        signature = inspect.signature(func)\n",
    "        type_hints = get_type_hints(func)\n",
    "\n",
    "        # Build the arguments schema dynamically\n",
    "        args_schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {},\n",
    "            \"required\": []\n",
    "        }\n",
    "        for param_name, param in signature.parameters.items():\n",
    "\n",
    "            if param_name in [\"action_context\", \"action_agent\"]:\n",
    "                continue  # Skip these parameters\n",
    "\n",
    "            def get_json_type(param_type):\n",
    "                if param_type == str:\n",
    "                    return \"string\"\n",
    "                elif param_type == int:\n",
    "                    return \"integer\"\n",
    "                elif param_type == float:\n",
    "                    return \"number\"\n",
    "                elif param_type == bool:\n",
    "                    return \"boolean\"\n",
    "                elif param_type == list:\n",
    "                    return \"array\"\n",
    "                elif param_type == dict:\n",
    "                    return \"object\"\n",
    "                else:\n",
    "                    return \"string\"\n",
    "\n",
    "            # Add parameter details\n",
    "            param_type = type_hints.get(param_name, str)  # Default to string if type is not annotated\n",
    "            param_schema = {\"type\": get_json_type(param_type)}  # Convert Python types to JSON schema types\n",
    "\n",
    "            args_schema[\"properties\"][param_name] = param_schema\n",
    "\n",
    "            # Add to required if not defaulted\n",
    "            if param.default == inspect.Parameter.empty:\n",
    "                args_schema[\"required\"].append(param_name)\n",
    "    else:\n",
    "        args_schema = parameters_override\n",
    "\n",
    "    # Return the metadata as a dictionary\n",
    "    return {\n",
    "        \"tool_name\": tool_name,\n",
    "        \"description\": description,\n",
    "        \"parameters\": args_schema,\n",
    "        \"function\": func,\n",
    "        \"terminal\": terminal,\n",
    "        \"tags\": tags or []\n",
    "    }\n",
    "\n",
    "\n",
    "def register_tool(tool_name=None, description=None, parameters_override=None, terminal=False, tags=None):\n",
    "    \"\"\"\n",
    "    A decorator to dynamically register a function in the tools dictionary with its parameters, schema, and docstring.\n",
    "\n",
    "    Parameters:\n",
    "        tool_name (str, optional): The name of the tool to register. Defaults to the function name.\n",
    "        description (str, optional): Override for the tool's description. Defaults to the function's docstring.\n",
    "        parameters_override (dict, optional): Override for the argument schema. Defaults to dynamically inferred schema.\n",
    "        terminal (bool, optional): Whether the tool is terminal. Defaults to False.\n",
    "        tags (List[str], optional): List of tags to associate with the tool.\n",
    "\n",
    "    Returns:\n",
    "        function: The wrapped function.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        # Use the reusable function to extract metadata\n",
    "        metadata = get_tool_metadata(\n",
    "            func=func,\n",
    "            tool_name=tool_name,\n",
    "            description=description,\n",
    "            parameters_override=parameters_override,\n",
    "            terminal=terminal,\n",
    "            tags=tags\n",
    "        )\n",
    "\n",
    "        # Register the tool in the global dictionary\n",
    "        tools[metadata[\"tool_name\"]] = {\n",
    "            \"description\": metadata[\"description\"],\n",
    "            \"parameters\": metadata[\"parameters\"],\n",
    "            \"function\": metadata[\"function\"],\n",
    "            \"terminal\": metadata[\"terminal\"],\n",
    "            \"tags\": metadata[\"tags\"] or []\n",
    "        }\n",
    "\n",
    "        for tag in metadata[\"tags\"]:\n",
    "            if tag not in tools_by_tag:\n",
    "                tools_by_tag[tag] = []\n",
    "            tools_by_tag[tag].append(metadata[\"tool_name\"])\n",
    "\n",
    "        return func\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a5438-d349-4d60-b571-5957c255e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Prompt:\n",
    "    # In Python, using mutable default arguments (like [] or {}) directly is dangerous, \n",
    "    # because they are shared across instances. To avoid this, field(default_factory=list) \n",
    "    # creates a new empty list every time an instance is created.\n",
    "    messages: List[Dict] = field(default_factory=list)\n",
    "    tools: List[Dict] = field(default_factory=list)\n",
    "    metadata: dict = field(default_factory=dict)\n",
    "\n",
    "\n",
    "def generate_response(prompt: Prompt) -> str:\n",
    "    \"\"\"Call LLM to get response\"\"\"\n",
    "    messages = prompt.messages\n",
    "    tools = prompt.tools\n",
    "\n",
    "    result = None\n",
    "\n",
    "    if not tools:\n",
    "        response = completion(\n",
    "            model=\"lm_studio/lmstudio\", # this test was done with 'gemma-3-12b-it'\n",
    "            messages=messages,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "    else:\n",
    "        response = completion(\n",
    "            model=\"lm_studio/lmstudio\", # this test was done with 'gemma-3-12b-it'\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "\n",
    "        if response.choices[0].message.tool_calls:\n",
    "            tool = response.choices[0].message.tool_calls[0]\n",
    "            result = {\n",
    "                \"tool\": tool.function.name,\n",
    "                \"args\": json.loads(tool.function.arguments),\n",
    "            }\n",
    "            result = json.dumps(result)\n",
    "        else:\n",
    "            result = response.choices[0].message.content\n",
    "    return result\n",
    "\n",
    "# When you use @dataclass(frozen=True), it makes the instance of the class immutable.\n",
    "# This means that after the object is created, its fields cannot be changed \n",
    "@dataclass(frozen=True)\n",
    "class Goal:\n",
    "    priority: int\n",
    "    name: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "class Action:\n",
    "    def __init__(self,\n",
    "                 name: str,\n",
    "                 function: Callable,\n",
    "                 description: str,\n",
    "                 parameters: Dict,\n",
    "                 terminal: bool = False):\n",
    "        self.name = name\n",
    "        self.function = function\n",
    "        self.description = description\n",
    "        self.terminal = terminal\n",
    "        self.parameters = parameters\n",
    "\n",
    "    def execute(self, **args) -> Any:\n",
    "        \"\"\"Execute the action's function\"\"\"\n",
    "        return self.function(**args)\n",
    "\n",
    "\n",
    "class ActionRegistry:\n",
    "    def __init__(self):\n",
    "        self.actions = {}\n",
    "\n",
    "    def register(self, action: Action):\n",
    "        self.actions[action.name] = action\n",
    "\n",
    "    def get_action(self, name: str) -> [Action, None]:\n",
    "        return self.actions.get(name, None)\n",
    "\n",
    "    def get_actions(self) -> List[Action]:\n",
    "        \"\"\"Get all registered actions\"\"\"\n",
    "        return list(self.actions.values())\n",
    "\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.items = []  # Basic conversation histor\n",
    "\n",
    "    def add_memory(self, memory: dict):\n",
    "        \"\"\"Add memory to working memory\"\"\"\n",
    "        self.items.append(memory)\n",
    "\n",
    "    def get_memories(self, limit: int = None) -> List[Dict]:\n",
    "        \"\"\"Get formatted conversation history for prompt\"\"\"\n",
    "        return self.items[:limit]\n",
    "\n",
    "    def copy_without_system_memories(self):\n",
    "        \"\"\"Return a copy of the memory without system memories\"\"\"\n",
    "        filtered_items = [m for m in self.items if m[\"type\"] != \"system\"]\n",
    "        memory = Memory()\n",
    "        memory.items = filtered_items\n",
    "        return memory\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    def execute_action(self, action: Action, args: dict) -> dict:\n",
    "        \"\"\"Execute an action and return the result.\"\"\"\n",
    "        try:\n",
    "            result = action.execute(**args)\n",
    "            return self.format_result(result)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"tool_executed\": False,\n",
    "                \"error\": str(e),\n",
    "                # This line comes from the traceback module in Python, which is used to extract,\n",
    "                # format, and print stack traces of exceptions.\n",
    "                \"traceback\": traceback.format_exc()\n",
    "            }\n",
    "\n",
    "    def format_result(self, result: Any) -> dict:\n",
    "        \"\"\"Format the result with metadata.\"\"\"\n",
    "        return {\n",
    "            \"tool_executed\": True,\n",
    "            \"result\": result,\n",
    "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        }\n",
    "\n",
    "\n",
    "class AgentLanguage:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def construct_prompt(self,\n",
    "                         actions: List[Action],\n",
    "                         environment: Environment,\n",
    "                         goals: List[Goal],\n",
    "                         memory: Memory) -> Prompt:\n",
    "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
    "\n",
    "\n",
    "    def parse_response(self, response: str) -> dict:\n",
    "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
    "\n",
    "\n",
    "\n",
    "class AgentFunctionCallingActionLanguage(AgentLanguage):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def format_goals(self, goals: List[Goal]) -> List:\n",
    "        # Map all goals to a single string that concatenates their description\n",
    "        # and combine into a single message of type system\n",
    "        sep = \"\\n-------------------\\n\"\n",
    "        goal_instructions = \"\\n\\n\".join([f\"{goal.name}:{sep}{goal.description}{sep}\" for goal in goals])\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": goal_instructions}\n",
    "        ]\n",
    "\n",
    "    def format_memory(self, memory: Memory) -> List:\n",
    "        \"\"\"Generate response from language model\"\"\"\n",
    "        # Map all environment results to a role:user messages\n",
    "        # Map all assistant messages to a role:assistant messages\n",
    "        # Map all user messages to a role:user messages\n",
    "        items = memory.get_memories()\n",
    "        mapped_items = []\n",
    "        for item in items:\n",
    "\n",
    "            content = item.get(\"content\", None)\n",
    "            if not content:\n",
    "                content = json.dumps(item, indent=4)\n",
    "\n",
    "            if item[\"type\"] == \"assistant\":\n",
    "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
    "            elif item[\"type\"] == \"environment\":\n",
    "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
    "            else:\n",
    "                mapped_items.append({\"role\": \"user\", \"content\": content})\n",
    "\n",
    "        return mapped_items\n",
    "\n",
    "    def format_actions(self, actions: List[Action]) -> [List,List]:\n",
    "        \"\"\"Generate response from language model\"\"\"\n",
    "\n",
    "        tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": action.name,\n",
    "                    # Include up to 1024 characters of the description\n",
    "                    \"description\": action.description[:1024],\n",
    "                    \"parameters\": action.parameters,\n",
    "                },\n",
    "            } for action in actions\n",
    "        ]\n",
    "\n",
    "        return tools\n",
    "\n",
    "    def construct_prompt(self,\n",
    "                         actions: List[Action],\n",
    "                         environment: Environment,\n",
    "                         goals: List[Goal],\n",
    "                         memory: Memory) -> Prompt:\n",
    "\n",
    "        prompt = []\n",
    "        prompt += self.format_goals(goals)\n",
    "        prompt += self.format_memory(memory)\n",
    "\n",
    "        tools = self.format_actions(actions)\n",
    "\n",
    "        return Prompt(messages=prompt, tools=tools)\n",
    "\n",
    "    def parse_response(self, response: str) -> dict:\n",
    "        \"\"\"Check that the LLM response is a valid json\"\"\"\n",
    "\n",
    "        try:\n",
    "            return json.loads(response)\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"tool\": \"terminate\",\n",
    "                \"args\": {\"message\":response}\n",
    "            }\n",
    "\n",
    "class PythonActionRegistry(ActionRegistry):\n",
    "    def __init__(self, tags: List[str] = None, tool_names: List[str] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.terminate_tool = None\n",
    "\n",
    "        for tool_name, tool_desc in tools.items():\n",
    "            if tool_name == \"terminate\":\n",
    "                self.terminate_tool = tool_desc\n",
    "\n",
    "            if tool_names and tool_name not in tool_names:\n",
    "                continue\n",
    "\n",
    "            tool_tags = tool_desc.get(\"tags\", [])\n",
    "            if tags and not any(tag in tool_tags for tag in tags):\n",
    "                continue\n",
    "\n",
    "            self.register(Action(\n",
    "                name=tool_name,\n",
    "                function=tool_desc[\"function\"],\n",
    "                description=tool_desc[\"description\"],\n",
    "                parameters=tool_desc.get(\"parameters\", {}),\n",
    "                terminal=tool_desc.get(\"terminal\", False)\n",
    "            ))\n",
    "\n",
    "    def register_terminate_tool(self):\n",
    "        if self.terminate_tool:\n",
    "            self.register(Action(\n",
    "                name=\"terminate\",\n",
    "                function=self.terminate_tool[\"function\"],\n",
    "                description=self.terminate_tool[\"description\"],\n",
    "                parameters=self.terminate_tool.get(\"parameters\", {}),\n",
    "                terminal=self.terminate_tool.get(\"terminal\", False)\n",
    "            ))\n",
    "        else:\n",
    "            raise Exception(\"Terminate tool not found in tool registry\")\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self,\n",
    "                 goals: List[Goal],\n",
    "                 agent_language: AgentLanguage,\n",
    "                 action_registry: ActionRegistry,\n",
    "                 generate_response: Callable[[Prompt], str],\n",
    "                 environment: Environment):\n",
    "        \"\"\"\n",
    "        Initialize an agent with its core GAME components\n",
    "        \"\"\"\n",
    "        self.goals = goals\n",
    "        self.generate_response = generate_response\n",
    "        self.agent_language = agent_language\n",
    "        self.actions = action_registry\n",
    "        self.environment = environment\n",
    "\n",
    "    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n",
    "        \"\"\"Build prompt with memory context\"\"\"\n",
    "        return self.agent_language.construct_prompt(\n",
    "            actions=actions.get_actions(),\n",
    "            environment=self.environment,\n",
    "            goals=goals,\n",
    "            memory=memory\n",
    "        )\n",
    "\n",
    "    def get_action(self, response):\n",
    "        invocation = self.agent_language.parse_response(response)\n",
    "        action = self.actions.get_action(invocation[\"tool\"])\n",
    "        return action, invocation\n",
    "\n",
    "    def should_terminate(self, response: str) -> bool:\n",
    "        action_def, _ = self.get_action(response)\n",
    "        return action_def.terminal\n",
    "\n",
    "    def set_current_task(self, memory: Memory, task: str):\n",
    "        memory.add_memory({\"type\": \"user\", \"content\": task})\n",
    "\n",
    "    def update_memory(self, memory: Memory, response: str, result: dict):\n",
    "        \"\"\"\n",
    "        Update memory with the agent's decision and the environment's response.\n",
    "        \"\"\"\n",
    "        new_memories = [\n",
    "            {\"type\": \"assistant\", \"content\": response},\n",
    "            {\"type\": \"environment\", \"content\": json.dumps(result)}\n",
    "        ]\n",
    "        for m in new_memories:\n",
    "            memory.add_memory(m)\n",
    "\n",
    "    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n",
    "        response = self.generate_response(full_prompt)\n",
    "        return response\n",
    "\n",
    "    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:\n",
    "        \"\"\"\n",
    "        Execute the GAME loop for this agent with a maximum iteration limit.\n",
    "        \"\"\"\n",
    "        memory = memory or Memory()\n",
    "        self.set_current_task(memory, user_input)\n",
    "\n",
    "        for _ in range(max_iterations):\n",
    "            # Construct a prompt that includes the Goals, Actions, and the current Memory\n",
    "            prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
    "\n",
    "            print(\"Agent thinking...\")\n",
    "            # Generate a response from the agent\n",
    "            response = self.prompt_llm_for_action(prompt)\n",
    "            print(f\"Agent Decision: {response}\")\n",
    "\n",
    "            # Determine which action the agent wants to execute\n",
    "            action, invocation = self.get_action(response)\n",
    "\n",
    "            # Execute the action in the environment\n",
    "            result = self.environment.execute_action(action, invocation[\"args\"])\n",
    "            print(f\"Action Result: {result}\")\n",
    "\n",
    "            # Update the agent's memory with information about what happened\n",
    "            self.update_memory(memory, response, result)\n",
    "\n",
    "            # Check if the agent has decided to terminate\n",
    "            if self.should_terminate(response):\n",
    "                break\n",
    "\n",
    "        return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8625a17-ad53-4824-9de3-778baabf6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_tool(tags=[\"document_processing\", \"invoices\"])\n",
    "def extract_invoice_data(action_context: ActionContext, document_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract standardized invoice data from document text.\n",
    "\n",
    "    This tool ensures consistent extraction of invoice information by using a fixed schema\n",
    "    and specialized prompting for invoice understanding. It will identify key fields like\n",
    "    invoice numbers, dates, amounts, and line items from any invoice format.\n",
    "\n",
    "    Args:\n",
    "        document_text: The text content of the invoice to process\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the extracted invoice data in a standardized format\n",
    "    \"\"\"\n",
    "    invoice_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\"invoice_number\", \"date\", \"total_amount\"],\n",
    "        \"properties\": {\n",
    "            \"invoice_number\": {\"type\": \"string\"},\n",
    "            \"date\": {\"type\": \"string\"},\n",
    "            \"total_amount\": {\"type\": \"number\"},\n",
    "            \"vendor\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"address\": {\"type\": \"string\"}\n",
    "                }\n",
    "            },\n",
    "            \"line_items\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"description\": {\"type\": \"string\"},\n",
    "                        \"quantity\": {\"type\": \"number\"},\n",
    "                        \"unit_price\": {\"type\": \"number\"},\n",
    "                        \"total\": {\"type\": \"number\"}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create a focused prompt for invoice extraction\n",
    "    extraction_prompt = f\"\"\"\n",
    "            You are an expert invoice analyzer. Extract invoice information accurately and \n",
    "            thoroughly. Pay special attention to:\n",
    "            - Invoice numbers (look for 'Invoice #', 'No.', 'Reference', etc.)\n",
    "            - Dates (focus on invoice date or issue date)\n",
    "            - Amounts (ensure you capture the total amount correctly)\n",
    "            - Line items (capture all individual charges)\n",
    "            \n",
    "            Stop and think step by step. Then, extract the invoice data from:\n",
    "            \n",
    "            <invoice>\n",
    "            {document_text}\n",
    "            </invoice>\n",
    "    \"\"\"\n",
    "\n",
    "    # Use prompt_llm_for_json with our specialized prompt\n",
    "    return prompt_llm_for_json(\n",
    "        action_context=action_context,\n",
    "        schema=invoice_schema,\n",
    "        prompt=extraction_prompt\n",
    "    )\n",
    "\n",
    "@register_tool(tags=[\"storage\", \"invoices\"])\n",
    "def store_invoice(action_context: ActionContext, invoice_data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Store an invoice in our invoice database. If an invoice with the same number\n",
    "    already exists, it will be updated.\n",
    "    \n",
    "    Args:\n",
    "        invoice_data: The processed invoice data to store\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the storage result and invoice number\n",
    "    \"\"\"\n",
    "    # Get our invoice storage from context\n",
    "    storage = action_context.get(\"invoice_storage\", {})\n",
    "    \n",
    "    # Extract invoice number for reference\n",
    "    invoice_number = invoice_data.get(\"invoice_number\")\n",
    "    if not invoice_number:\n",
    "        raise ValueError(\"Invoice data must contain an invoice number\")\n",
    "    \n",
    "    # Store the invoice\n",
    "    storage[invoice_number] = invoice_data\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"message\": f\"Stored invoice {invoice_number}\",\n",
    "        \"invoice_number\": invoice_number\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73143f39-31d8-4264-8a60-9e7e078a6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_invoice_agent():\n",
    "    # Create action registry with our invoice tools\n",
    "    action_registry = PythonActionRegistry()\n",
    "    \n",
    "    # Create our base environment\n",
    "    environment = PythonEnvironment()\n",
    "    \n",
    "    # Define our invoice processing goals\n",
    "    goals = [\n",
    "        Goal(\n",
    "            name=\"Persona\",\n",
    "            description=\"You are an Invoice Processing Agent, specialized in handling and storing invoice data.\"\n",
    "        ),\n",
    "        Goal(\n",
    "            name=\"Process Invoices\",\n",
    "            description=\"\"\"\n",
    "            Your goal is to process invoices by extracting their data and storing it properly.\n",
    "            For each invoice:\n",
    "            1. Extract all important information including numbers, dates, amounts, and line items\n",
    "            2. Store the extracted data indexed by invoice number\n",
    "            3. Provide confirmation of successful processing\n",
    "            4. Handle any errors appropriately\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Create the agent\n",
    "    return Agent(\n",
    "        goals=goals,\n",
    "        agent_language=AgentFunctionCallingActionLanguage(),\n",
    "        action_registry=action_registry,\n",
    "        generate_response=generate_response,\n",
    "        environment=environment\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9830b5-40c9-4791-8d05-dd03dc35c473",
   "metadata": {},
   "source": [
    "## Persona Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cefc6-4f1b-4c6c-9381-7437fa6aaf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_tool()\n",
    "def prompt_expert(action_context: ActionContext, description_of_expert: str, prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a response from an expert persona.\n",
    "    \n",
    "    The expert's background and specialization should be thoroughly described to ensure\n",
    "    responses align with their expertise. The prompt should be focused on topics within\n",
    "    their domain of knowledge.\n",
    "    \n",
    "    Args:\n",
    "        description_of_expert: Detailed description of the expert's background and expertise\n",
    "        prompt: The specific question or task for the expert\n",
    "        \n",
    "    Returns:\n",
    "        The expert's response\n",
    "    \"\"\"\n",
    "    generate_response = action_context.get(\"llm\")\n",
    "    response = generate_response(Prompt(messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": f\"Act as the following expert and respond accordingly: {description_of_expert}\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393bad6-8268-42af-9484-80614b0b83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_tool(tags=[\"documentation\"])\n",
    "def generate_technical_documentation(action_context: ActionContext, code_or_feature: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate technical documentation by consulting a senior technical writer.\n",
    "    This expert focuses on creating clear, comprehensive documentation for developers.\n",
    "    \n",
    "    Args:\n",
    "        code_or_feature: The code or feature to document\n",
    "    \"\"\"\n",
    "    return prompt_expert(\n",
    "        action_context=action_context,\n",
    "        description_of_expert=\"\"\"\n",
    "        You are a senior technical writer with 15 years of experience in software documentation.\n",
    "        You have particular expertise in:\n",
    "        - Writing clear and precise API documentation\n",
    "        - Explaining complex technical concepts to developers\n",
    "        - Documenting implementation details and integration points\n",
    "        - Creating code examples that illustrate key concepts\n",
    "        - Identifying and documenting important caveats and edge cases\n",
    "        \n",
    "        Your documentation is known for striking the perfect balance between completeness\n",
    "        and clarity. You understand that good technical documentation serves as both\n",
    "        a reference and a learning tool.\n",
    "        \"\"\",\n",
    "        prompt=f\"\"\"\n",
    "        Please create comprehensive technical documentation for the following code or feature:\n",
    "\n",
    "        {code_or_feature}\n",
    "\n",
    "        Your documentation should include:\n",
    "        1. A clear overview of the feature's purpose and functionality\n",
    "        2. Detailed explanation of the implementation approach\n",
    "        3. Key interfaces and integration points\n",
    "        4. Usage examples with code snippets\n",
    "        5. Important considerations and edge cases\n",
    "        6. Performance implications if relevant\n",
    "        \n",
    "        Focus on providing information that developers need to effectively understand\n",
    "        and work with this code.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "@register_tool(tags=[\"testing\"])\n",
    "def design_test_suite(action_context: ActionContext, feature_description: str) -> str:\n",
    "    \"\"\"\n",
    "    Design a comprehensive test suite by consulting a senior QA engineer.\n",
    "    This expert focuses on creating thorough test coverage with attention to edge cases.\n",
    "    \n",
    "    Args:\n",
    "        feature_description: Description of the feature to test\n",
    "    \"\"\"\n",
    "    return prompt_expert(\n",
    "        action_context=action_context,\n",
    "        description_of_expert=\"\"\"\n",
    "        You are a senior QA engineer with 12 years of experience in test design and automation.\n",
    "        Your expertise includes:\n",
    "        - Comprehensive test strategy development\n",
    "        - Unit, integration, and end-to-end testing\n",
    "        - Performance and stress testing\n",
    "        - Security testing considerations\n",
    "        - Test automation best practices\n",
    "        \n",
    "        You are particularly skilled at identifying edge cases and potential failure modes\n",
    "        that others might miss. Your test suites are known for their thoroughness and\n",
    "        their ability to catch issues early in the development cycle.\n",
    "        \"\"\",\n",
    "        prompt=f\"\"\"\n",
    "        Please design a comprehensive test suite for the following feature:\n",
    "\n",
    "        {feature_description}\n",
    "\n",
    "        Your test design should cover:\n",
    "        1. Unit tests for individual components\n",
    "        2. Integration tests for component interactions\n",
    "        3. End-to-end tests for critical user paths\n",
    "        4. Performance test scenarios if relevant\n",
    "        5. Edge cases and error conditions\n",
    "        6. Test data requirements\n",
    "        \n",
    "        For each test category, provide:\n",
    "        - Specific test scenarios\n",
    "        - Expected outcomes\n",
    "        - Important edge cases to consider\n",
    "        - Potential testing challenges\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "@register_tool(tags=[\"code_quality\"])\n",
    "def perform_code_review(action_context: ActionContext, code: str) -> str:\n",
    "    \"\"\"\n",
    "    Review code and suggest improvements by consulting a senior software architect.\n",
    "    This expert focuses on code quality, architecture, and best practices.\n",
    "    \n",
    "    Args:\n",
    "        code: The code to review\n",
    "    \"\"\"\n",
    "    return prompt_expert(\n",
    "        action_context=action_context,\n",
    "        description_of_expert=\"\"\"\n",
    "        You are a senior software architect with 20 years of experience in code review\n",
    "        and software design. Your expertise includes:\n",
    "        - Software architecture and design patterns\n",
    "        - Code quality and maintainability\n",
    "        - Performance optimization\n",
    "        - Scalability considerations\n",
    "        - Security best practices\n",
    "        \n",
    "        You have a talent for identifying subtle design issues and suggesting practical\n",
    "        improvements that enhance code quality without over-engineering.\n",
    "        \"\"\",\n",
    "        prompt=f\"\"\"\n",
    "        Please review the following code and provide detailed improvement suggestions:\n",
    "\n",
    "        {code}\n",
    "\n",
    "        Consider and address:\n",
    "        1. Code organization and structure\n",
    "        2. Potential design pattern applications\n",
    "        3. Performance optimization opportunities\n",
    "        4. Error handling completeness\n",
    "        5. Edge case handling\n",
    "        6. Maintainability concerns\n",
    "        \n",
    "        For each suggestion:\n",
    "        - Explain the current issue\n",
    "        - Provide the rationale for change\n",
    "        - Suggest specific improvements\n",
    "        - Note any trade-offs to consider\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "@register_tool(tags=[\"communication\"])\n",
    "def write_feature_announcement(action_context: ActionContext, \n",
    "                             feature_details: str,\n",
    "                             audience: str) -> str:\n",
    "    \"\"\"\n",
    "    Write a feature announcement by consulting a product marketing expert.\n",
    "    This expert focuses on clear communication of technical features to different audiences.\n",
    "    \n",
    "    Args:\n",
    "        feature_details: Technical details of the feature\n",
    "        audience: Target audience for the announcement (e.g., \"technical\", \"business\")\n",
    "    \"\"\"\n",
    "    return prompt_expert(\n",
    "        action_context=action_context,\n",
    "        description_of_expert=\"\"\"\n",
    "        You are a senior product marketing manager with 12 years of experience in\n",
    "        technical product communication. Your expertise includes:\n",
    "        - Translating technical features into clear value propositions\n",
    "        - Crafting compelling product narratives\n",
    "        - Adapting messaging for different audience types\n",
    "        - Building excitement while maintaining accuracy\n",
    "        - Creating clear calls to action\n",
    "        \n",
    "        You excel at finding the perfect balance between technical accuracy and\n",
    "        accessibility, ensuring your communications are both precise and engaging.\n",
    "        \"\"\",\n",
    "        prompt=f\"\"\"\n",
    "        Please write a feature announcement for the following feature:\n",
    "\n",
    "        {feature_details}\n",
    "\n",
    "        This announcement is intended for a {audience} audience.\n",
    "\n",
    "        Your announcement should include:\n",
    "        1. A compelling introduction\n",
    "        2. Clear explanation of the feature\n",
    "        3. Key benefits and use cases\n",
    "        4. Technical details (adapted to audience)\n",
    "        5. Implementation requirements\n",
    "        6. Next steps or call to action\n",
    "        \n",
    "        Ensure the tone and technical depth are appropriate for a {audience} audience.\n",
    "        Focus on conveying both the value and the practical implications of this feature.\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307aea3d-6128-40a9-b35e-8fc6cd3fbf65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
