{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f36d95a-3e5d-493b-9b57-7950bec500e0",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f72eefb-d5be-46cc-b70f-889be95fdd86",
   "metadata": {},
   "source": [
    "Make sure you have 'LM Studio' running locally. 'LM Studio' loaded models listen on:\n",
    "`http://localhost:1234/v1/chat/completions`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e29fa-b820-44d8-8b09-58c2bd134e46",
   "metadata": {},
   "source": [
    "# Install required Python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d52be5da-c606-4744-a662-ac09c15f07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LiteLLM (https://github.com/BerriAI/litellm)\n",
    "\n",
    "# Uncomment the below line to install litellm\n",
    "# !pip install litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc4a99-46c8-48df-902a-f2d5f6fb740d",
   "metadata": {},
   "source": [
    "# Code samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe786c4-7a53-4db2-a864-80afc071158d",
   "metadata": {},
   "source": [
    "## A simple agent who lists files in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a30fdfa-3e5e-4221-be98-4b8241042ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Imports ...\n",
    "#\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from litellm import completion\n",
    "from typing import List, Dict\n",
    "\n",
    "#\n",
    "# LM Studio URL \n",
    "#\n",
    "os.environ['LM_STUDIO_API_BASE'] = \"http://localhost:1234/v1\"\n",
    "os.environ['LM_STUDIO_API_KEY'] = \"42\" # Not really used. Set it to a non empty value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135855a6-ab84-49d1-b841-350082f4a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Helper functions\n",
    "#\n",
    "\n",
    "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
    "    \"\"\"Extract code block from response\"\"\"\n",
    "\n",
    "    if not '```' in response:\n",
    "        return response\n",
    "\n",
    "    code_block = response.split('```')[1].strip()\n",
    "\n",
    "    if code_block.startswith(block_type):\n",
    "        code_block = code_block[len(block_type):].strip()\n",
    "\n",
    "    return code_block\n",
    "\n",
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"Call LLM to get a response.\"\"\"\n",
    "    response = completion(\n",
    "        model=\"lm_studio/lmstudio\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def parse_action(response: str) -> Dict:\n",
    "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
    "    try:\n",
    "        response = extract_markdown_block(response, \"action\")\n",
    "        response_json = json.loads(response)\n",
    "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
    "            return response_json\n",
    "        else:\n",
    "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f30cc38e-9d73-450f-a280-1c455562b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define the tools/actions available to the agent\n",
    "#\n",
    "\n",
    "def list_files() -> List[str]:\n",
    "    \"\"\"List files in the current directory.\"\"\"\n",
    "    return os.listdir(\".\")\n",
    "\n",
    "def read_file(file_name: str) -> str:\n",
    "    \"\"\"Read a file's contents.\"\"\"\n",
    "    try:\n",
    "        with open(file_name, \"r\") as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: {file_name} not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ad5a2c-da71-4452-9bb8-1440b4faafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These agent rules are specified in the system message and play\n",
    "# a critical role in ensuring the agent interacts predictably\n",
    "# and within its defined boundaries.\n",
    "\n",
    "#\n",
    "# Define system instructions (Agent Rules)\n",
    "#\n",
    "agent_rules = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "You are an AI agent that can perform tasks by using available tools.\n",
    "\n",
    "Available tools:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"list_files\": {\n",
    "        \"description\": \"Lists all files in the current directory.\",\n",
    "        \"parameters\": {}\n",
    "    },\n",
    "    \"read_file\": {\n",
    "        \"description\": \"Reads the content of a file.\",\n",
    "        \"parameters\": {\n",
    "            \"file_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The name of the file to read.\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"terminate\": {\n",
    "        \"description\": \"Ends the agent loop and provides a summary of the task.\",\n",
    "        \"parameters\": {\n",
    "            \"message\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Summary message to return to the user.\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "If a user asks about files, documents, or content, first list the files before reading them.\n",
    "\n",
    "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
    "\n",
    "Important!!! Every response MUST have an action.\n",
    "You must ALWAYS respond in this format:\n",
    "\n",
    "<Stop and think step by step. Parameters map to args. Insert a rich description of your step by step thoughts here.>\n",
    "\n",
    "```action\n",
    "{\n",
    "    \"tool_name\": \"insert tool_name\",\n",
    "    \"args\": {...fill in any required arguments here...}\n",
    "}\n",
    "```\"\"\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e8b6aa6-9c20-4698-939b-47d022b784c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What would you like me to do?  list files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent thinking...\n",
      "Agent response: Okay, I understand the instructions. The user wants me to list the files first before reading them and to always respond with an action. My first step is to identify what files are available in the current directory so that I can proceed accordingly.\n",
      "\n",
      "```action\n",
      "{\n",
      "    \"tool_name\": \"list_files\",\n",
      "    \"args\": {}\n",
      "}\n",
      "```\n",
      "Action result: {'result': ['module2.ipynb', 'module1.ipynb', 'README.md', '.ipynb_checkpoints']}\n",
      "Agent thinking...\n",
      "Agent response: Okay, I have listed the files in the current directory: `module2.ipynb`, `module1.ipynb`, `README.md`, and `.ipynb_checkpoints`. Now, let's assume the user is interested in understanding the content of one of these files. Since there are multiple options, I will start by reading the `README.md` file as it often contains general information about a project or directory.\n",
      "\n",
      "```action\n",
      "{\n",
      "    \"tool_name\": \"read_file\",\n",
      "    \"args\": {\n",
      "        \"file_name\": \"README.md\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "Action result: {'result': '# AI Agents and Agentic AI with Python & Generative AI\\n\\nURL: https://www.coursera.org/learn/ai-agents-python/\\n\\nAll the examples from the course have been readapted to use `LM Studio` instead of `OpenAI’s GPT`.'}\n",
      "Agent thinking...\n",
      "Agent response: I've successfully read the contents of `README.md`. The file indicates this is a collection of examples related to AI Agents and Agentic AI, adapted to use LM Studio instead of OpenAI’s GPT. Now that I have listed the files and read the README, I will terminate the conversation and provide a summary.\n",
      "\n",
      "```action\n",
      "{\n",
      "    \"tool_name\": \"terminate\",\n",
      "    \"args\": {\n",
      "        \"message\": \"I listed the available files (`module2.ipynb`, `module1.ipynb`, `README.md`, `.ipynb_checkpoints`) and read the content of `README.md`, which describes examples for AI Agents using LM Studio.\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "I listed the available files (`module2.ipynb`, `module1.ipynb`, `README.md`, `.ipynb_checkpoints`) and read the content of `README.md`, which describes examples for AI Agents using LM Studio.\n"
     ]
    }
   ],
   "source": [
    "# Initialize agent parameters\n",
    "iterations = 0\n",
    "max_iterations = 10\n",
    "\n",
    "user_task = input(\"What would you like me to do? \")\n",
    "\n",
    "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
    "\n",
    "##################\n",
    "# The Agent Loop #\n",
    "##################\n",
    "while iterations < max_iterations:\n",
    "    # 1. Construct prompt: Combine agent rules with memory\n",
    "    prompt = agent_rules + memory\n",
    "\n",
    "    # 2. Generate response from LLM\n",
    "    print(\"Agent thinking...\")\n",
    "    response = generate_response(prompt)\n",
    "    print(f\"Agent response: {response}\")\n",
    "\n",
    "    # 3. Parse response to determine action\n",
    "    action = parse_action(response)\n",
    "    result = \"Action executed\"\n",
    "\n",
    "    if action[\"tool_name\"] == \"list_files\":\n",
    "        result = {\"result\": list_files()}\n",
    "    elif action[\"tool_name\"] == \"read_file\":\n",
    "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
    "    elif action[\"tool_name\"] == \"error\":\n",
    "        result = {\"error\": action[\"args\"][\"message\"]}\n",
    "    elif action[\"tool_name\"] == \"terminate\":\n",
    "        print(action[\"args\"][\"message\"])\n",
    "        break\n",
    "    else:\n",
    "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
    "\n",
    "    print(f\"Action result: {result}\")\n",
    "\n",
    "    # 5. Update memory with response and results\n",
    "    memory.extend([\n",
    "        {\"role\": \"assistant\", \"content\": response},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
    "    ])\n",
    "\n",
    "    # 6. Check termination condition\n",
    "    if action[\"tool_name\"] == \"terminate\":\n",
    "        break\n",
    "\n",
    "    iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b53dc-e1ce-431d-9965-5941800f8913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
